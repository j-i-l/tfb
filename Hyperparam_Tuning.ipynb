{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58174bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import general_param as gparams\n",
    "from custom import KmerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356e94fe",
   "metadata": {},
   "source": [
    "### Note on Pipelines\n",
    "\n",
    "We only start to use pipelines here in the hyper-parameter tuning part.\n",
    "\n",
    "Since we want to optimize our feature engineering by adapting the k-mer size and \n",
    "ngram_range, we **directly load the cleaned data here and include the feature engineering steps into\n",
    "the pipeline**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8373148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_data = pd.read_pickle(gparams.cleanded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c777444",
   "metadata": {},
   "source": [
    "We do as before and use the presence of the binding 'strength' as non-binding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f497810",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sequence_data.strength.apply(lambda x: 1 if x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895062c",
   "metadata": {},
   "source": [
    "# Hyper-parameter  Tuning\n",
    "\n",
    "Given that we do not know the size of the binding area we should modify both the kmer size and the ngram_range.\n",
    "\n",
    "### kmer size tuning\n",
    "\n",
    "We used a custom function to create the k-mers, so we need some extra steps to tune this parameter.\n",
    "\n",
    "Actually, the only thing we need to do is to create a custom transromer by subclassing `sklearn.base.BaseEstimator` and mixin with the `sklearn.base.TransformerMixin`.\n",
    "\n",
    "See [./custom.py](./custom.py) for the definition of our custom `KmerTransformer`, that basically promotes the `get_kmers` function from [./Feature_Engineering.ipynb](./Feature_Engineering.ipynb) into a transformer.\n",
    "\n",
    "### ngram_range tuning\n",
    "\n",
    "With `CountVectorizer` we already have a Transformer for this step, so we simply can add `ngram_range` to the parameter grid. Also, since _numpy 1.16.0_ linspace supports array like objects as start/stop, so this one is easy.\n",
    "\n",
    "### SVC params tuning\n",
    "\n",
    "This is an existing classifier so the parameters we want to tune can simply be added to the grid.\n",
    "\n",
    "#### Note\n",
    "Due to time constraints we simply ommit the tuning of the SVC params and focus on the k-mer sizes and ngram ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f44e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer = KmerTransformer(size=3)\n",
    "vect = CountVectorizer(analyzer='word')\n",
    "svc = SVC(kernel='linear', random_state=gparams.random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5067f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('kmer', kmer),\n",
    "    ('vect', vect),\n",
    "    ('svc', svc)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "505f160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "   'kmer__size': np.linspace(2, 6, 5, dtype=int),\n",
    "   'vect__ngram_range': list(map(tuple, np.linspace((1,1), (1, 20), 20, dtype=int))),\n",
    "    # svc__...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0414088",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipeline, grid_params, error_score='raise')\n",
    "clf_fitted = clf.fit(sequence_data.sequence, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c1f8196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9705\n",
      "Best Params:  {'kmer__size': 5, 'vect__ngram_range': (1, 6)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(\"Best Params: \", clf.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
