{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ccb4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import general_param as gparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3247fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmers_labeled = pd.read_pickle(gparams.kmers_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c657fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kmers</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ctgaa tgaag gaagc aagcc agcct gcctt ccttt cttt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gagcc agccc gcccc cccca cccac ccacc cacct acct...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tccag ccagc cagct agctt gcttt ctttc tttcg ttcg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tgcat gcatt cattc attcg ttcgc tcgca cgcag gcag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aggcg ggcgg gcggg cgggt gggtt ggttc gttcg ttcg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>cgaat gaatg aatgc atgct tgctc gctcc ctccg tccg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>ctcca tccat ccatg catgg atggg tgggg ggggg gggg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>cggca ggcag gcagg caggg agggc gggcc ggccg gccg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>acgac cgacg gacgg acggt cggta ggtag gtagg tagg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>ttgtg tgtga gtgag tgagc gagcg agcgt gcgta cgta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  kmers  labels\n",
       "0     ctgaa tgaag gaagc aagcc agcct gcctt ccttt cttt...       1\n",
       "1     gagcc agccc gcccc cccca cccac ccacc cacct acct...       1\n",
       "2     tccag ccagc cagct agctt gcttt ctttc tttcg ttcg...       1\n",
       "3     tgcat gcatt cattc attcg ttcgc tcgca cgcag gcag...       1\n",
       "4     aggcg ggcgg gcggg cgggt gggtt ggttc gttcg ttcg...       1\n",
       "...                                                 ...     ...\n",
       "5995  cgaat gaatg aatgc atgct tgctc gctcc ctccg tccg...       0\n",
       "5996  ctcca tccat ccatg catgg atggg tgggg ggggg gggg...       0\n",
       "5997  cggca ggcag gcagg caggg agggc gggcc ggccg gccg...       0\n",
       "5998  acgac cgacg gacgg acggt cggta ggtag gtagg tagg...       0\n",
       "5999  ttgtg tgtga gtgag tgagc gagcg agcgt gcgta cgta...       0\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmers_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e6329",
   "metadata": {},
   "source": [
    "We do the last feature engineering step directly here, so to keep the bag-of-words encoding in sparse form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "994d51a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, gparams.ngram_nbr))\n",
    "X = vectorizer.fit_transform(kmers_labeled.kmers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8126fb1a",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "We can go with any classification method here, so we will set up a procedure in which we can simply substitute the metod.\n",
    "\n",
    "We will consider:\n",
    "\n",
    "- [support vector classification](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "- [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- [random forests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn-ensemble-randomforestclassifier)\n",
    "- [decision trees](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "- [gradient boosting classifiers](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "- [~~linear discriminant analysis~~](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html)\n",
    "- [~~neural networks~~](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f455742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, x_train, x_test, y_train, y_test):\n",
    "    '''\n",
    "    Perform a fit and retur the f1_score.\n",
    "    \n",
    "    Note that this method perfoms no in-place operations\n",
    "    on the model, so the model is not affected by this\n",
    "    function.\n",
    "    '''\n",
    "    _model = clone(model)\n",
    "    start = datetime.now()\n",
    "    _modle = _model.fit(x_train, y_train)\n",
    "    y_pred = _model.predict(x_test)\n",
    "    print('\\n=======\\n')\n",
    "    print(_model)\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f'Duration {datetime.now() - start}')\n",
    "    return f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628daf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, kmers_labeled.labels, test_size = 0.2, random_state=gparams.random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d7406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear', random_state=gparams.random_state)\n",
    "logres = LogisticRegression(random_state=gparams.random_state)\n",
    "dtc = DecisionTreeClassifier(class_weight='balanced', random_state=gparams.random_state)\n",
    "frc = RandomForestClassifier(max_depth=2, class_weight='balanced_subsample', random_state=gparams.random_state)\n",
    "gbc = GradientBoostingClassifier(random_state=gparams.random_state)\n",
    "\n",
    "# lda does not fly with this input dim on my laptop (requires dense input)\n",
    "# lda = LinearDiscriminantAnalysis()\n",
    "# lda_pipe = make_pipeline(FunctionTransformer(lambda x: x.todense(), accept_sparse=True), lda)\n",
    "\n",
    "# this will take forever I fear:\n",
    "#mlpc = MLPClassifier(hidden_layer_sizes=(10,), random_state=gparams.random_state, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [svc, logres, dtc, frc]:\n",
    "    fit_model(model, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1634c4",
   "metadata": {},
   "source": [
    "### Decision\n",
    "\n",
    "For the sake of time, we will continue with the support vector classifier only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
